{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1)import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2) Load and describe data\n",
    "Master = pd.read_csv(\"Master.csv\",header=0,sep=\"|\",encoding=\"ISO-8859-1\")\n",
    "Train = pd.read_csv(\"Thirdparty_train.csv\",header=0,sep=\"|\",encoding=\"ISO-8859-1\")\n",
    "Test = pd.read_csv(\"Thirdparty_test.csv\",header=0,encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 450256 entries, 0 to 450255\n",
      "Data columns (total 2 columns):\n",
      "company_id    450256 non-null int64\n",
      "name          450256 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Master.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 3 columns):\n",
      "train_index    100000 non-null int64\n",
      "name           100000 non-null object\n",
      "company_id     100000 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98788"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train = Train.drop_duplicates(subset=\"name\",keep=False)\n",
    "Train.to_csv(\"D:\\\\Personal\\\\ING\\\\STrain2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 3) Pre Processing of the data\n",
    "def removespecial(review_text):\n",
    "    ## Removes special characters like &,<,>,,,', etc##\n",
    "    review_text = re.sub(r\"\\?\", \" \", str(review_text))\n",
    "    review_text= re.sub(r'\\W+', ' ', str(review_text))\n",
    "    return review_text\n",
    "\n",
    "def preparing_Dataset(source_data,train_data, train=1):\n",
    "    ##Returns Pre-Processed Data\n",
    "    if train ==1:\n",
    "        G_Name = source_data[\"name\"].tolist()\n",
    "        G_Id = source_data[\"company_id\"].tolist()\n",
    "        source_data[\"name\"] = source_data[\"name\"].apply(removespecial).tolist()\n",
    "        STrain_Name = train_data[\"name\"].tolist()\n",
    "        STrain_Id = train_data[\"company_id\"].tolist()\n",
    "        train_data[\"name\"] = train_data[\"name\"].apply(removespecial).tolist()\n",
    "        df = pd.concat([source_data[[\"name\"]],train_data[[\"name\"]]],axis =0).reset_index()\n",
    "        return df[\"name\"],G_Name,G_Id,STrain_Name,STrain_Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final_Names,Master_Names,Master_Id,Train_names,Train_Id = preparing_Dataset(Master,Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 4) Vectorization of the Data\n",
    "def ngrams(text, n=3):\n",
    "    ## ngram generation\n",
    "    text = re.sub(r'[,-./]|\\sBD',r'', text)\n",
    "    ngram = zip(*[text[i:] for i in range(n)])\n",
    "    return [''.join(ng) for ng in ngram]\n",
    "\n",
    "def TFIDF(texts,G_count,S_count):\n",
    "    ## TFIDF vector creation\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "    print(tfidf_matrix.shape)\n",
    "    print(G_count+S_count)\n",
    "    return tfidf_matrix[0:G_count,:],tfidf_matrix[G_count:G_count+S_count,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549044, 67923)\n",
      "549044\n"
     ]
    }
   ],
   "source": [
    "Master_Matrix,Train_Matrix = TFIDF(Final_Names,len(Master),len(Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450256, 67923)\n"
     ]
    }
   ],
   "source": [
    "print(Master_Matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98788, 67923)\n"
     ]
    }
   ],
   "source": [
    "print(Train_Matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Cosine Distance Calculation\n",
    "\n",
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    B = B.tocsr()\n",
    "\n",
    "    M, K1 = A.shape\n",
    "    K2, N = B.shape\n",
    "\n",
    "    idx_dtype = np.int32\n",
    "\n",
    "    nnz_max = M*ntop\n",
    "\n",
    "    indptr = np.empty(M+1, dtype=idx_dtype)\n",
    "    indices = np.empty(nnz_max, dtype=idx_dtype)\n",
    "    data = np.empty(nnz_max, dtype=A.dtype)\n",
    "    print(\"temp\")\n",
    "    ct.sparse_dot_topn(\n",
    "        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "        np.asarray(A.indices, dtype=idx_dtype),\n",
    "        A.data,\n",
    "        np.asarray(B.indptr, dtype=idx_dtype),\n",
    "        np.asarray(B.indices, dtype=idx_dtype),\n",
    "        B.data,\n",
    "        ntop,\n",
    "        lower_bound,\n",
    "        indptr, indices, data)\n",
    "    print(\"temp\")\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp\n",
      "temp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Cosine_Matrix = awesome_cossim_top(Train_Matrix,Master_Matrix.transpose(),1,0)\n",
    "with open(\"Cosine_Matrix.pickle\", 'wb') as handle:\n",
    "    pickle.dump(Cosine_Matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 5) Matrix to Data Frame\n",
    "\n",
    "def get_Final_Data(cosine_Matrix,G_CompanyName,G_CompanyId,STrain_CompanyName,STrain_CompanyId):\n",
    "    no_zero = cosine_Matrix.nonzero()\n",
    "    sparse_row = no_zero[0]\n",
    "    sparse_col = no_zero[1]\n",
    "\n",
    "    # if ntop:\n",
    "    #     nr_match = ntop\n",
    "    # else:\n",
    "    nr_match = sparse_col.size\n",
    "    Strain_data = np.empty([nr_match],dtype=object)\n",
    "    Strain_companyId = np.empty([nr_match], dtype=object)\n",
    "    G_data = np.empty([nr_match], dtype=object)\n",
    "    G_companyId = np.empty([nr_match], dtype=object)\n",
    "    score = np.zeros(nr_match)\n",
    "    for index in range(0, nr_match):\n",
    "        Strain_data[index] = STrain_CompanyName[sparse_row[index]]\n",
    "        Strain_companyId[index] = STrain_CompanyId[sparse_row[index]]\n",
    "        G_data[index] = G_CompanyName[sparse_col[index]]\n",
    "        G_companyId[index] = G_CompanyId[sparse_col[index]]\n",
    "        score[index] = cosine_Matrix.data[index]\n",
    "\n",
    "    return pd.DataFrame({\"Strain_data\":Strain_data,\n",
    "                         \"Strain_CompanyId\":Strain_companyId,\n",
    "                         \"G_data\":G_data,\n",
    "                         \"G_CompanyId\":G_companyId,\n",
    "                         \"score\":score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98788, 450256)\n"
     ]
    }
   ],
   "source": [
    "print(Cosine_Matrix.shape)\n",
    "final = get_Final_Data(Cosine_Matrix,Master_Names,Master_Id,Train_names,Train_Id)\n",
    "final['output']=final.apply(lambda x: 1 if (x['G_CompanyId']==x['strain_CompanyId']) else 0, axis=1)\n",
    "final.to_csv(\"final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 6) Classifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.read_csv(\"final.csv\",header=0,encoding=\"ISO-8859-1\")\n",
    "final_train,final_test = train_test_split(final,test_size=0.30,random_state=2)\n",
    "LRC = LogisticRegression(C=10, penalty='l2')\n",
    "LRC.fit(final_train[[\"score\"]],final_train[['output']])\n",
    "\n",
    "# clf2 = svm.LinearSVC(C=1.,dual=False,loss='l2', penalty='l2')\n",
    "# clf2.fit(final_train[[\"score\"]],final_train[['output']])\n",
    "\n",
    "# clf3 = RandomForestClassifier(bootstrap ='True',max_depth=6,max_features='sqrt',n_estimators=50)\n",
    "# clf3.fit(final_train[[\"score\"]],final_train[['output']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7) Prediction\n",
    "predict = LRC.predict(final_test[['score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9947</td>\n",
       "      <td>3202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3167</td>\n",
       "      <td>13219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0      1\n",
       "Actual                \n",
       "0          9947   3202\n",
       "1          3167  13219"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 8) Model Validation\n",
    "# using cross tab\n",
    "pd.crosstab(final_test['output'],predict, rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79286336, 0.7827096 , 0.77835799, 0.79315347, 0.78670923,\n",
       "       0.77713291, 0.78119559, 0.78612885, 0.78670923, 0.78961114,\n",
       "       0.77822932, 0.78432511, 0.78984035, 0.78635704, 0.78258345,\n",
       "       0.78664731, 0.78838897, 0.77997097, 0.79419448, 0.77474601])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9) Cross validation to check whether the model will behave in a same way for new data\n",
    "cross_val_score(LRC,final_train[[\"score\"]],final_train['output'],cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.76      0.76     13149\n",
      "          1       0.81      0.81      0.81     16386\n",
      "\n",
      "avg / total       0.78      0.78      0.78     29535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10) Precison - Recall Matrix\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(final_test['output'],predict)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 11) Persisting the model\n",
    "pickle.dump(LRC,open('finalized_model.sav','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
